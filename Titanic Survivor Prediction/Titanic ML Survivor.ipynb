{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')\n",
    "gender_submission_df = pd.read_csv('./gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing our Training + Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_trimmed = train_df.drop(labels=['Name', 'PassengerId', 'Ticket', 'Embarked', 'Cabin'], axis=1)\n",
    "X_trimmed = train_df.drop(labels=['Name', 'PassengerId', 'Ticket', 'Embarked', 'Cabin', 'SibSp', 'Fare'], axis=1)\n",
    "survived = train_df['Survived'].copy()\n",
    "X_trimmed = X_trimmed.drop(labels=['Survived'], axis=1)\n",
    "\n",
    "\n",
    "X_test_trimmed = test_df.drop(labels=['Name', 'PassengerId', 'Ticket', 'Embarked', 'Cabin', 'SibSp', 'Fare'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass     Sex   Age  Parch\n",
      "0         3    male  34.5      0\n",
      "1         3  female  47.0      0\n",
      "2         2    male  62.0      0\n",
      "3         3    male  27.0      0\n",
      "4         3  female  22.0      1\n",
      "..      ...     ...   ...    ...\n",
      "413       3    male   NaN      0\n",
      "414       1  female  39.0      0\n",
      "415       3    male  38.5      0\n",
      "416       3    male   NaN      0\n",
      "417       3    male   NaN      1\n",
      "\n",
      "[418 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_trimmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Some Nice Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bar_chart(features):\n",
    "    survive = train_df[train_df.Survived==1][features].value_counts()\n",
    "    dead = train_df[train_df.Survived==0][features].value_counts()\n",
    "    df = pd.DataFrame([survive,dead])\n",
    "    df.index = [\"survived\",\"dead\"]\n",
    "    df.plot(kind=\"bar\",stacked=True,figsize=(10,5))\n",
    "    \n",
    "bar_chart(\"Sex\")\n",
    "bar_chart(\"Pclass\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_trimmed['Age'] = X_trimmed['Age'].fillna(method='pad')\n",
    "X_test_trimmed['Age'] = X_test_trimmed['Age'].fillna(method='pad')\n",
    "# X_test_trimmed['Fare'] = X_test_trimmed['Fare'].fillna(method='pad')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "X_trimmed.iloc[:, 1] = encoder.fit_transform(X_trimmed.iloc[:, 1])\n",
    "X_test_trimmed.iloc[:, 1] = encoder.fit_transform(X_test_trimmed.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for NANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(X_trimmed.isnull().values.any())\n",
    "print(X_test_trimmed.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_trimmed_scaled = scaler.fit_transform(X_trimmed)\n",
    "X_test_trimmed_scaled = scaler.fit_transform(X_test_trimmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at our Trimmed Data One Last Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         0.27117366 0.        ]\n",
      " [0.         0.         0.4722292  0.        ]\n",
      " [1.         0.         0.32143755 0.        ]\n",
      " ...\n",
      " [1.         0.         0.23347575 0.33333333]\n",
      " [0.         1.         0.32143755 0.        ]\n",
      " [1.         1.         0.39683338 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_trimmed_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "ID = pd.Series(range(892, 1310))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.88\n",
      "[[504  65]\n",
      " [ 45 277]]\n",
      "Model has accuracy percentage of: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90       569\n",
      "           1       0.81      0.86      0.83       322\n",
      "\n",
      "    accuracy                           0.88       891\n",
      "   macro avg       0.86      0.87      0.87       891\n",
      "weighted avg       0.88      0.88      0.88       891\n",
      "\n",
      "Accuracy of K-NN classifier on training set: 0.89\n",
      "[[547  98]\n",
      " [  2 244]]\n",
      "Model has accuracy percentage of: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92       645\n",
      "           1       0.71      0.99      0.83       246\n",
      "\n",
      "    accuracy                           0.89       891\n",
      "   macro avg       0.85      0.92      0.87       891\n",
      "weighted avg       0.92      0.89      0.89       891\n",
      "\n",
      "Accuracy of K-NN classifier on training set: 0.89\n",
      "[[515  65]\n",
      " [ 34 277]]\n",
      "Model has accuracy percentage of: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       580\n",
      "           1       0.81      0.89      0.85       311\n",
      "\n",
      "    accuracy                           0.89       891\n",
      "   macro avg       0.87      0.89      0.88       891\n",
      "weighted avg       0.89      0.89      0.89       891\n",
      "\n",
      "Accuracy of K-NN classifier on training set: 0.90\n",
      "[[530  69]\n",
      " [ 19 273]]\n",
      "Model has accuracy percentage of: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92       599\n",
      "           1       0.80      0.93      0.86       292\n",
      "\n",
      "    accuracy                           0.90       891\n",
      "   macro avg       0.88      0.91      0.89       891\n",
      "weighted avg       0.91      0.90      0.90       891\n",
      "\n",
      "Accuracy of K-NN classifier on training set: 0.89\n",
      "[[518  63]\n",
      " [ 31 279]]\n",
      "Model has accuracy percentage of: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92       581\n",
      "           1       0.82      0.90      0.86       310\n",
      "\n",
      "    accuracy                           0.89       891\n",
      "   macro avg       0.88      0.90      0.89       891\n",
      "weighted avg       0.90      0.89      0.90       891\n",
      "\n",
      "Accuracy of K-NN classifier on training set: 0.90\n",
      "[[536  74]\n",
      " [ 13 268]]\n",
      "Model has accuracy percentage of: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.92       610\n",
      "           1       0.78      0.95      0.86       281\n",
      "\n",
      "    accuracy                           0.90       891\n",
      "   macro avg       0.88      0.92      0.89       891\n",
      "weighted avg       0.92      0.90      0.90       891\n",
      "\n",
      "Accuracy of K-NN classifier on training set: 0.90\n",
      "[[536  74]\n",
      " [ 13 268]]\n",
      "Model has accuracy percentage of: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.92       610\n",
      "           1       0.78      0.95      0.86       281\n",
      "\n",
      "    accuracy                           0.90       891\n",
      "   macro avg       0.88      0.92      0.89       891\n",
      "weighted avg       0.92      0.90      0.90       891\n",
      "\n",
      "Accuracy of K-NN classifier on training set: 0.90\n",
      "[[536  74]\n",
      " [ 13 268]]\n",
      "Model has accuracy percentage of: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.92       610\n",
      "           1       0.78      0.95      0.86       281\n",
      "\n",
      "    accuracy                           0.90       891\n",
      "   macro avg       0.88      0.92      0.89       891\n",
      "weighted avg       0.92      0.90      0.90       891\n",
      "\n",
      "Accuracy of K-NN classifier on training set: 0.90\n",
      "[[536  74]\n",
      " [ 13 268]]\n",
      "Model has accuracy percentage of: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.92       610\n",
      "           1       0.78      0.95      0.86       281\n",
      "\n",
      "    accuracy                           0.90       891\n",
      "   macro avg       0.88      0.92      0.89       891\n",
      "weighted avg       0.92      0.90      0.90       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    knn = KNeighborsClassifier(n_neighbors = i, weights='distance')\n",
    "    knn.fit(X_trimmed_scaled, survived)\n",
    "\n",
    "    print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "         .format(knn.score(X_trimmed_scaled, survived)))\n",
    "\n",
    "\n",
    "    knn_predict = knn.predict(X_test_trimmed_scaled)\n",
    "    y1 = np.array(knn_predict)\n",
    "    sol = pd.DataFrame({'PassengerId':ID, 'Survived':y1})\n",
    "    sol.to_csv('Solution_KNN.csv', index=False)\n",
    "\n",
    "    knn_trained_predict = knn.predict(X_trimmed_scaled)\n",
    "\n",
    "    cm = confusion_matrix(knn_trained_predict, survived)\n",
    "    # sns.heatmap(cm, annot=True)\n",
    "    print(cm)\n",
    "\n",
    "    print(\"Model has accuracy percentage of: \")\n",
    "    print(classification_report(knn_trained_predict, survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest on training set: 0.89\n",
      "Model has accuracy percentage of: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       583\n",
      "           1       0.80      0.89      0.85       308\n",
      "\n",
      "    accuracy                           0.89       891\n",
      "   macro avg       0.87      0.89      0.88       891\n",
      "weighted avg       0.89      0.89      0.89       891\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAXGklEQVR4nO3deXwV1fnH8c+TTUCWIDFsQUBABa2ioPJr1eKGola0iqX9tVLFpla0gmAFrVbEXVmkKDYWFK1LQbEgLoAg2tYFFywKSImIEgiEfVVIcs/vjzvwC5Dce2OWwx2+b17zysyZuXPO9ZXXk8dnzsyYcw4REal9Kb4HICJysFIAFhHxRAFYRMQTBWAREU8UgEVEPEmr6Q6K1y3TNAvZT9ujLvY9BDkAFWz43Kp6jsrEnPSsI6vcX1UoAxYR8aTGM2ARkVoVKfU9goQpAItIuJSW+B5BwlSCEJFQcS6S8BKPmS03s8/M7FMz+yhoO8zMZpnZ0uBn46DdzGyMmeWb2QIzOyne+RWARSRcIpHEl8Sc6Zzr7JzrGmwPAWY75zoAs4NtgJ5Ah2DJBcbFO7ECsIiEi4skvnw/vYCJwfpE4JIy7U+7qPeBTDNrHutECsAiEi6R0sSX+Bww08w+NrPcoK2pc64QIPiZHbS3BFaU+WxB0FYhXYQTkXCpRGYbBNXcMk15zrm8Mts/cs6tMrNsYJaZfRHrdOWNJlb/CsAiEiquErMggmCbF2P/quBnkZm9DJwCrDGz5s65wqDEUBQcXgC0KvPxHGBVrP5VghCRcKmmi3BmdqiZNdi9DvQAPgemAX2Dw/oCU4P1acCVwWyIbsDm3aWKiigDFpFw+f4X1/bVFHjZzCAaK59zzr1hZh8Ck8ysH/AN0Ds4/jXgAiAf2AFcFa8DBWARCZdquhPOObcMOKGc9vXA2eW0O6B/ZfpQABaRcKm+DLjGKQCLSLgk0a3ICsAiEi6J3+HmnQKwiISKc3oamoiIH6oBi4h4ohKEiIgnyoBFRDwpLfY9goQpAItIuKgEISLiiUoQIiKeKAMWEfFEAVhExA+ni3AiIp6oBiwi4olKECIinigDFhHxRBmwiIgnyoBFRDwp0QPZRUT8UAYsIuKJasAiIp4oAxYR8UQZsIiIJ8qARUQ80SwIERFPnPM9goQpAItIuKgGLCLiiQKwiIgnuggnIuJJaanvESRMAVhEwkUlCBERTxSARUQ8UQ1YRMQPF9E8YBERP1SCEBHxJIlmQaT4HoCISLWKRBJfEmBmqWY238ymB9ttzewDM1tqZn83s4yg/ZBgOz/Y3ybeuRWARSRcqjkAAzcCi8tsPwCMcs51ADYC/YL2fsBG51x7YFRwXEwqQcTQ47K+HFqvHikpKaSmpjJpwpi99k+fMYfxz04GoF7dutw++HqO6XBklfrctWsXQ4ePYNGSpWQ2asjDdw2lZfOmvDvvE0Y//iTFxSWkp6cxqH8/Tu3SuUp9Se1r2LABD40ZxtHHtMcBg264nWuu/RXt2reJ7m/UgC2bt3Lejy/3Os6kVo0P4zGzHOBC4B7gJjMz4CzgF8EhE4E7gXFAr2Ad4EVgrJmZcxUPSAE4jgl/vp/GmY3K3deyRTOeGvsgjRo24J/vfciwB8fw/BOjEzrvysI13HbPCJ4a++Be7VOmz6Rhg/q8PmkCr705l5GPTWDE8KE0zmzI2AfuJPvwJixdtpzfDvwjc6b+rcrfT2rXsPuGMHf2v/ntr28iPT2NunXrcl2/wXv23z58MFu3bPM4whCo3otwo4E/AA2C7SbAJufc7mdeFgAtg/WWwAoA51yJmW0Ojl9X0cnjBmAzO4ZoZG8JOGAVMM05tzjmBw8CJ/6g05714489hjVF///f+ZUZc3h28lSKi0s4/tij+eOg/qSmpsY955x/vsd1/X4JQI/up3PvyHE45+h4VPs9x7Rv25qdu3axa9cuMjIyqvEbSU2q3+BQTv1hFwb2vw2A4uISiou37nXMTy45n5/1utrH8MKjEtPQzCwXyC3TlOecywv2XQQUOec+NrPuuz9SzmlcAvvKFbMGbGa3AC8EJ54HfBisP29mQ2J9NgzMjNyBt3HF1TcweeprMY+dMn0Gp3XrCsCXy7/hjdlv88zjI3hp4qOkpKQwfeZbCfVZtHY9zbKzAEhLS6X+ofXYtHnLXsfMmvsvOh7VTsE3yRzROocN6zYycuzdvDF3Mg89Moy69eru2X/q/3RhbdF6vlr2jcdRhkBpacKLcy7POde1zJJX5kw/Ai42s+VE4+BZRDPiTDPbnbzmEE1KIZoNtwII9jcCNsQaarwMuB9wrHOuuGyjmY0EFgL3l/ehsn9VHhtxN9dc+fM43RyYnhk3guzDm7B+4yZ+M+BW2rZuRdfOP9jvuHkf/4cp02fyzLiHAfjgo09Z9EU+ffrdCMDOnTs5rHEmAL8fehcrV62huKSYwjVruaxvfwB+eUUvLr2wB+WVi6Jlp6j8ZV8z8rEJ5I26p9q/r9SstLQ0jjuhI7cPuZf5H3/GsPuG0H9APx6+dywAvS67gKlTYv+hl/hcNZUgnHNDgaEAQQY82Dn3v2Y2GbicaFDuC0wNPjIt2H4v2D8nVv0X4gfgCNAC+Hqf9ubBvooGngfkARSvW5Y8t6XsI/vwJgA0aZzJ2Wf8kM8WLdkvAC/J/4o77h/N4yOGk9moIQDOOS7ueQ4Df3fVfuccc98dQMU14KbZWawuWkez7MMpKSll2/YdNGoYLT+tLlrLjbcO597bB3NETotq/75SswpXraZw1Rrmf/wZAK9OnUn/AdcAkJqaSs+LzuGCs67wOcRwqPk74W4BXjCzu4H5wPigfTzwjJnlE818+8Q7UbxpaAOA2Wb2upnlBcsbwGyiUzNCa8e337F9+4496+/O+4QOR7bZ65jC1UUMuHU4991xM22OyNnT3q1rZ2bN/RfrN24CYPOWraxavSahfs88rRtTX3sTgJlz/8mpXU7AzNiydRvX3fwnBvz215x0/LHV8A2ltq0tWs+qlas5MpjxcNqPu7F0yZcAnN69G18uXUbhqsR+TyQGF0l8SfSUzs11zl0UrC9zzp3inGvvnOvtnNsZtH8XbLcP9i+Ld96YGbBz7g0zOwo4hehFOCNa5/jQOZc8t5t8D+s3bOTGW4cDUFpSygU9unNat678/eVXAfjZpRcy7snn2LxlK3c//CjAnqlq7dq25obfXEnugNuIuAjpaWncdtN1tGjWNG6/P73oPIYOf4ieV1xNo4YNeGhYtNT+/EuvsKJgFY8/9TyPP/U8AHmj76FJUNqQ5HD7Lffy5788QEZGOl8vX8Gg628H4OJLe/KPl173PLqQSKJnQVicEkWVJXMJQmpO26Mu9j0EOQAVbPi8vJkElbL9jj4Jx5xD73qhyv1VheYBi0i46HGUIiKeJFEJQgFYREKluqah1QYFYBEJF2XAIiKeKACLiHiSRA9kVwAWkVDRO+FERHxRABYR8USzIEREPFEGLCLiiQKwiIgfrlQlCBERP5QBi4j4oWloIiK+KACLiHiSPCVgBWARCRdXkjwRWAFYRMIleeKvArCIhIsuwomI+KIMWETED2XAIiK+KAMWEfHDlfgeQeIUgEUkVJLorfQKwCISMgrAIiJ+KAMWEfFEAVhExBNXar6HkDAFYBEJFWXAIiKeuIgyYBERL5QBi4h44pwyYBERL5QBi4h4EkmiWRApvgcgIlKdXMQSXmIxszpmNs/M/mNmC81sWNDe1sw+MLOlZvZ3M8sI2g8JtvOD/W3ijVUBWERCpboCMLATOMs5dwLQGTjfzLoBDwCjnHMdgI1Av+D4fsBG51x7YFRwXEwKwCISKs4lvsQ+j3POuW3BZnqwOOAs4MWgfSJwSbDeK9gm2H+2mcWM8grAIhIq1ZgBY2apZvYpUATMAr4ENjm356GXBUDLYL0lsAIg2L8ZaBLr/ArAIhIqzlnCi5nlmtlHZZbcvc/lSp1znYEc4BSgY3ldBj/Li+gx82zNghCRUCmtxCwI51wekJfAcZvMbC7QDcg0s7Qgy80BVgWHFQCtgAIzSwMaARtinVcZsIiESmUy4FjM7HAzywzW6wLnAIuBt4DLg8P6AlOD9WnBNsH+Oc7FrjQrAxaRUKnGZ0E0ByaaWSrRZHWSc266mS0CXjCzu4H5wPjg+PHAM2aWTzTz7ROvAwVgEQmVeLMbEj+PWwCcWE77MqL14H3bvwN6V6YPBWARCRU9DU1ExJPSSPJc2lIAFpFQqa4SRG1QABaRUInocZQiIn7oecAiIp6oBFFG3Ran13QXkoTezz7Z9xAkpFSCEBHxRLMgREQ8SaIKhAKwiISLShAiIp5oFoSIiCdJ9FJkBWARCRdX7nPRD0wKwCISKiUqQYiI+KEMWETEE9WARUQ8UQYsIuKJMmAREU9KlQGLiPiRRG8kUgAWkXCJKAMWEfFDD+MREfFEF+FERDyJmEoQIiJelPoeQCUoAItIqGgWhIiIJ5oFISLiiWZBiIh4ohKEiIgnmoYmIuJJqTJgERE/lAGLiHiiACwi4kkSvRJOAVhEwkUZsIiIJ8l0K3KK7wGIiFSniCW+xGJmrczsLTNbbGYLzezGoP0wM5tlZkuDn42DdjOzMWaWb2YLzOykeGNVABaRUIlUYomjBBjknOsIdAP6m1knYAgw2znXAZgdbAP0BDoESy4wLl4HCsAiEirVFYCdc4XOuU+C9a3AYqAl0AuYGBw2EbgkWO8FPO2i3gcyzax5rD4UgEUkVFwllkSZWRvgROADoKlzrhCiQRrIDg5rCawo87GCoK1CCsAiEiqVqQGbWa6ZfVRmyd33fGZWH3gJGOCc2xKj6/KqyjHjvGZBiEioVGYWhHMuD8iraL+ZpRMNvs8656YEzWvMrLlzrjAoMRQF7QVAqzIfzwFWxepfGbCIhEoEl/ASi5kZMB5Y7JwbWWbXNKBvsN4XmFqm/cpgNkQ3YPPuUkVFlAGLSKhU440YPwJ+BXxmZp8GbbcC9wOTzKwf8A3QO9j3GnABkA/sAK6K14ECsIiESnU9kN059y/Kr+sCnF3O8Q7oX5k+FIBFJFR0K7KIiCclljwvJVIAFpFQSZ7wqwAsIiGjEoSIiCfxppcdSBSARSRUkif8KgCLSMioBCEi4klpEuXACsAiEirKgEVEPHHKgEVE/FAGLBxyyCHMnfMSGYccQlpaKlOmvMqwu0aQ95eH6dLlBMxg6dKvuLrfALZv3+F7uJKg9OZZtH3kRtIPz4SIY+1zMykaP32vY1Ib1KPtmIFktMzCUlNZ/Zd/sH7SnCr1m5pZn3aPDSajVTa7VhTx5e8eonTzdg679AyaXfdTACLbv+ProY/z7eLlVeor2SXTNDQ9jrKG7Ny5k3N6XEGXrufSpWsPzuvRnVNPOYlBg++kS9dzOanLuaz4ZiX9r4v7wCQ5kJSWUnDXkyw88wYWX/wHsvv2pE6HnL0OObzvBXy7dAWLegxkSe8/0uqOq7D0xHKdBv9zHG1G/n6/9ub9L2PLvxfw+enXseXfC2jW/zIAdn6zhiWX38aicwew6pFJtH7wuqp/xyRXE2/EqCkKwDVod2abnp5GWno6zjm2bt22Z3+dunWIPkBJkkVx0UZ2fL4MiGac3y4tIKNZk70Pco7UQ+sCkHJoHUo2bcOVRB8T3vTaS+g4/SE6zRpNi0F9Eu43s8cprJ/8FgDrJ79F4/NOBWD7x0so3bw9uv7JEjKaN6nwHAeLElzCi28KwDUoJSWFjz6cSeHKBcye/Q7zPpwPwF+fGMnKFZ9yzNHtGfvoBM+jlO8rIyebescdybb5/92rveipV6nTIYfjP57AsW8+woo7/grO0fCMztRp24LFF93Moh4DqfeDdtQ/tVNCfaVlZVJctBGI/hFIa9Jov2Oy+pzD5rc+qfoXS3KuEv98+94B2Mwq/H/nsu9ZikS2f98ukl4kEqHryT1o3bYrJ3c9kWOPPRqAa35zE61an8TiL5ZyRe+LPY9Svo+UenVol3cLK+4cT2Tbt3vta9T9RL5d+BULulzNovMGcsTduaTUr0vDMzrT8IzOdJoxik5vjKRO+xzqtG0BwDGvPEinGaNo/VB/MnucHD1mxiga/rhzQuNp8MPjyOpzDgX3PF3t3zXZVONr6WtcVS7CDQOeLG9H2fcspWW09P9nxrPNm7fw9jvvcl6P7ixcuASIBufJk6cx6KbfMfHpSZ5HKJVhaam0y7uFDS+/zabX399vf5Mrzmb1o9HXh+1cvpqdK9ZQt30OmFE49kXWPTtzv8988ZM/ANEacJPeZ7H8pjF77S9Zt4n07MYUF20kPbsxJes379lXt2NrWj94PUt/dRelm7ZW51dNSgdCZpuomBmwmS2oYPkMaFpLY0xKWVmH0ahRQwDq1KnD2Wedzn//u4x27drsOeaiC89lyZJ8TyOU76v1w9fzXX4Ba56YVu7+XSvX0vC04wFIy2pEnXYt2fn1ara8PZ+sPueQUq8OAOnNDiu3lFCeTbPm0aT3mQA06X0mm2bOAyCjRRbtnhjCVzeOYudXMd//eNAIUwbcFDgP2LhPuwHv1siIQqJ586ZMGD+a1NQUUlJSePHFV3j1tTd5+62XadCwPmbGggWL6H/9UN9DlUqof3JHsi4/kx2Ll9NpxigAVj7wNzJaZAGw9m8zKHxkEm1G3kinNx/BgIJ7n6Zk41a2vPMpdTrkcMy0BwCIbP+Wr34/eq9stiKFY6fQ7vGbyepzDrtWruPLax8EoPnAn5GW2YDW914LgCspZfGFg2vgmyeP0iS6sG2xrsKb2XjgyeDdSPvue84594t4HagEIeV5P/tk30OQA1DXgn9U9A62hP2i9aUJx5znvn65yv1VRcwM2DnXL8a+uMFXRKS2JVMNWHfCiUioHAi13UQpAItIqCTTrcgKwCISKipBiIh4kkyzIBSARSRUVIIQEfFEF+FERDxRDVhExBOVIEREPEmmZ2wrAItIqOi19CIinqgEISLiiUoQIiKeKAMWEfFE09BERDxJpluR9VZkEQmVCC7hJR4zm2BmRWb2eZm2w8xslpktDX42DtrNzMaYWX7w6raT4p1fAVhEQqU6AzDwFHD+Pm1DgNnOuQ7A7GAboCfQIVhygXHxTq4ALCKh4pxLeEngXO8AG/Zp7gVMDNYnApeUaX/aRb0PZJpZ81jnVw1YREKlFmZBNHXOFQI45wrNLDtobwmsKHNcQdBWWNGJlAGLSKi4Svwzs1wz+6jMkluFrst7wWfMvwbKgEUkVEpd4g+kdM7lAXmV7GKNmTUPst/mQFHQXgC0KnNcDrAq1omUAYtIqFRnDbgC04C+wXpfYGqZ9iuD2RDdgM27SxUVUQYsIqFSnTVgM3se6A5kmVkB8CfgfmCSmfUDvgF6B4e/BlwA5AM7gKvinV8BWERCpTrvhHPO/byCXWeXc6wD+lfm/ArAIhIqkSS6E04BWERCRc+CEBHxpDKzIHxTABaRUFEJQkTEE5UgREQ8UQYsIuKJMmAREU9KXanvISRMAVhEQkUv5RQR8UQv5RQR8UQZsIiIJ5oFISLiiWZBiIh4oluRRUQ8UQ1YRMQT1YBFRDxRBiwi4onmAYuIeKIMWETEE82CEBHxRBfhREQ8UQlCRMQT3QknIuKJMmAREU+SqQZsyfTXItmZWa5zLs/3OOTAot+Lg1eK7wEcZHJ9D0AOSPq9OEgpAIuIeKIALCLiiQJw7VKdT8qj34uDlC7CiYh4ogxYRMQTBWAREU8UgGuJmZ1vZkvMLN/Mhvgej/hnZhPMrMjMPvc9FvFDAbgWmFkq8CjQE+gE/NzMOvkdlRwAngLO9z0I8UcBuHacAuQ755Y553YBLwC9PI9JPHPOvQNs8D0O8UcBuHa0BFaU2S4I2kTkIKYAXDusnDbN/xM5yCkA144CoFWZ7RxglaexiMgBQgG4dnwIdDCztmaWAfQBpnkek4h4pgBcC5xzJcD1wAxgMTDJObfQ76jENzN7HngPONrMCsysn+8xSe3SrcgiIp4oAxYR8UQBWETEEwVgERFPFIBFRDxRABYR8UQBWETEEwVgERFP/g9BhLlxyLsu4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 500, min_samples_split=5)\n",
    "clf.fit(X_trimmed_scaled, survived)\n",
    "\n",
    "print('Accuracy of RandomForest on training set: {:.2f}'\n",
    "     .format(clf.score(X_trimmed_scaled, survived)))\n",
    "\n",
    "clf_predict = clf.predict(X_test_trimmed_scaled)\n",
    "y1 = np.array(clf_predict)\n",
    "sol = pd.DataFrame({'PassengerId':ID, 'Survived':y1})\n",
    "sol.to_csv('Solution_CLF.csv', index=False)\n",
    "\n",
    "clf_trained_predict = clf.predict(X_trimmed_scaled)\n",
    "\n",
    "cm = confusion_matrix(clf_trained_predict, survived)\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "print(\"Model has accuracy percentage of: \")\n",
    "print(classification_report(clf_trained_predict, survived))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Deep Neural Networks to Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "# Adding the input layer and the 2nd hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
    "\n",
    "# Adding the input layer and the 1st hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "# Adding the input layer and the 2nd hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=4, activation='linear'))\n",
    "\n",
    "# Adding the input layer and the third hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=2, activation='sigmoid'))\n",
    "\n",
    "# Adding the output layer\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.7412 - accuracy: 0.3838\n",
      "Epoch 2/200\n",
      "9/9 [==============================] - 0s 997us/step - loss: 0.7322 - accuracy: 0.3838\n",
      "Epoch 3/200\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.7239 - accuracy: 0.3838\n",
      "Epoch 4/200\n",
      "9/9 [==============================] - 0s 740us/step - loss: 0.7168 - accuracy: 0.3838\n",
      "Epoch 5/200\n",
      "9/9 [==============================] - 0s 913us/step - loss: 0.7102 - accuracy: 0.3838\n",
      "Epoch 6/200\n",
      "9/9 [==============================] - 0s 775us/step - loss: 0.7043 - accuracy: 0.3838\n",
      "Epoch 7/200\n",
      "9/9 [==============================] - 0s 970us/step - loss: 0.6987 - accuracy: 0.3838\n",
      "Epoch 8/200\n",
      "9/9 [==============================] - 0s 911us/step - loss: 0.6937 - accuracy: 0.3838\n",
      "Epoch 9/200\n",
      "9/9 [==============================] - 0s 969us/step - loss: 0.6890 - accuracy: 0.3838\n",
      "Epoch 10/200\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.6849 - accuracy: 0.4456\n",
      "Epoch 11/200\n",
      "9/9 [==============================] - 0s 905us/step - loss: 0.6809 - accuracy: 0.6274\n",
      "Epoch 12/200\n",
      "9/9 [==============================] - 0s 634us/step - loss: 0.6774 - accuracy: 0.6689\n",
      "Epoch 13/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.6743 - accuracy: 0.7183\n",
      "Epoch 14/200\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.6714 - accuracy: 0.7340\n",
      "Epoch 15/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6686 - accuracy: 0.7576\n",
      "Epoch 16/200\n",
      "9/9 [==============================] - 0s 734us/step - loss: 0.6659 - accuracy: 0.7643\n",
      "Epoch 17/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6633 - accuracy: 0.7677\n",
      "Epoch 18/200\n",
      "9/9 [==============================] - 0s 664us/step - loss: 0.6607 - accuracy: 0.7722\n",
      "Epoch 19/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6579 - accuracy: 0.7744\n",
      "Epoch 20/200\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.6553 - accuracy: 0.7744\n",
      "Epoch 21/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.6525 - accuracy: 0.7744\n",
      "Epoch 22/200\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.6497 - accuracy: 0.7688\n",
      "Epoch 23/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6469 - accuracy: 0.7710\n",
      "Epoch 24/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.6440 - accuracy: 0.7744\n",
      "Epoch 25/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.6412 - accuracy: 0.7767\n",
      "Epoch 26/200\n",
      "9/9 [==============================] - 0s 890us/step - loss: 0.6384 - accuracy: 0.7722\n",
      "Epoch 27/200\n",
      "9/9 [==============================] - 0s 551us/step - loss: 0.6356 - accuracy: 0.7767\n",
      "Epoch 28/200\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.6329 - accuracy: 0.7778\n",
      "Epoch 29/200\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.6303 - accuracy: 0.7789\n",
      "Epoch 30/200\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.6278 - accuracy: 0.7800\n",
      "Epoch 31/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6254 - accuracy: 0.7845\n",
      "Epoch 32/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.6230 - accuracy: 0.7845\n",
      "Epoch 33/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6206 - accuracy: 0.7856\n",
      "Epoch 34/200\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.6185 - accuracy: 0.7856\n",
      "Epoch 35/200\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.6162 - accuracy: 0.7845\n",
      "Epoch 36/200\n",
      "9/9 [==============================] - 0s 771us/step - loss: 0.6141 - accuracy: 0.7845\n",
      "Epoch 37/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6120 - accuracy: 0.7845\n",
      "Epoch 38/200\n",
      "9/9 [==============================] - 0s 780us/step - loss: 0.6100 - accuracy: 0.7845\n",
      "Epoch 39/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6080 - accuracy: 0.7856\n",
      "Epoch 40/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6061 - accuracy: 0.7856\n",
      "Epoch 41/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.6042 - accuracy: 0.7856\n",
      "Epoch 42/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.6023 - accuracy: 0.7856\n",
      "Epoch 43/200\n",
      "9/9 [==============================] - 0s 775us/step - loss: 0.6005 - accuracy: 0.7868\n",
      "Epoch 44/200\n",
      "9/9 [==============================] - 0s 651us/step - loss: 0.5987 - accuracy: 0.7868\n",
      "Epoch 45/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5969 - accuracy: 0.7890\n",
      "Epoch 46/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5952 - accuracy: 0.7890\n",
      "Epoch 47/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5935 - accuracy: 0.7890\n",
      "Epoch 48/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5919 - accuracy: 0.7901\n",
      "Epoch 49/200\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.5901 - accuracy: 0.7901\n",
      "Epoch 50/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5885 - accuracy: 0.7901\n",
      "Epoch 51/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5868 - accuracy: 0.7901\n",
      "Epoch 52/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5852 - accuracy: 0.7912\n",
      "Epoch 53/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5838 - accuracy: 0.7890\n",
      "Epoch 54/200\n",
      "9/9 [==============================] - 0s 583us/step - loss: 0.5822 - accuracy: 0.7879\n",
      "Epoch 55/200\n",
      "9/9 [==============================] - 0s 558us/step - loss: 0.5807 - accuracy: 0.7901\n",
      "Epoch 56/200\n",
      "9/9 [==============================] - 0s 667us/step - loss: 0.5790 - accuracy: 0.7912\n",
      "Epoch 57/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5776 - accuracy: 0.7912\n",
      "Epoch 58/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5761 - accuracy: 0.7901\n",
      "Epoch 59/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5746 - accuracy: 0.7901\n",
      "Epoch 60/200\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.5732 - accuracy: 0.7901\n",
      "Epoch 61/200\n",
      "9/9 [==============================] - 0s 678us/step - loss: 0.5717 - accuracy: 0.7912\n",
      "Epoch 62/200\n",
      "9/9 [==============================] - 0s 550us/step - loss: 0.5703 - accuracy: 0.7912\n",
      "Epoch 63/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5689 - accuracy: 0.7912\n",
      "Epoch 64/200\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.5675 - accuracy: 0.7912\n",
      "Epoch 65/200\n",
      "9/9 [==============================] - 0s 773us/step - loss: 0.5661 - accuracy: 0.7912\n",
      "Epoch 66/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5648 - accuracy: 0.7912\n",
      "Epoch 67/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5634 - accuracy: 0.7924\n",
      "Epoch 68/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5620 - accuracy: 0.7924\n",
      "Epoch 69/200\n",
      "9/9 [==============================] - 0s 779us/step - loss: 0.5607 - accuracy: 0.7924\n",
      "Epoch 70/200\n",
      "9/9 [==============================] - 0s 623us/step - loss: 0.5595 - accuracy: 0.7924\n",
      "Epoch 71/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5581 - accuracy: 0.7924\n",
      "Epoch 72/200\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.5568 - accuracy: 0.7935\n",
      "Epoch 73/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5557 - accuracy: 0.7924\n",
      "Epoch 74/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5542 - accuracy: 0.7935\n",
      "Epoch 75/200\n",
      "9/9 [==============================] - 0s 670us/step - loss: 0.5529 - accuracy: 0.7935\n",
      "Epoch 76/200\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.5516 - accuracy: 0.7935\n",
      "Epoch 77/200\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.5504 - accuracy: 0.7935\n",
      "Epoch 78/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5491 - accuracy: 0.7935\n",
      "Epoch 79/200\n",
      "9/9 [==============================] - 0s 671us/step - loss: 0.5478 - accuracy: 0.7935\n",
      "Epoch 80/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5466 - accuracy: 0.7935\n",
      "Epoch 81/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5454 - accuracy: 0.7946\n",
      "Epoch 82/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5442 - accuracy: 0.7935\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 665us/step - loss: 0.5430 - accuracy: 0.7946\n",
      "Epoch 84/200\n",
      "9/9 [==============================] - 0s 624us/step - loss: 0.5420 - accuracy: 0.7946\n",
      "Epoch 85/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5407 - accuracy: 0.7946\n",
      "Epoch 86/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5395 - accuracy: 0.7946\n",
      "Epoch 87/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5383 - accuracy: 0.7946\n",
      "Epoch 88/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5376 - accuracy: 0.7935\n",
      "Epoch 89/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5362 - accuracy: 0.7957\n",
      "Epoch 90/200\n",
      "9/9 [==============================] - 0s 737us/step - loss: 0.5350 - accuracy: 0.7969\n",
      "Epoch 91/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5337 - accuracy: 0.7969\n",
      "Epoch 92/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5328 - accuracy: 0.7957\n",
      "Epoch 93/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5327 - accuracy: 0.7969\n",
      "Epoch 94/200\n",
      "9/9 [==============================] - 0s 886us/step - loss: 0.5307 - accuracy: 0.7980\n",
      "Epoch 95/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5295 - accuracy: 0.7957\n",
      "Epoch 96/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5283 - accuracy: 0.7957\n",
      "Epoch 97/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5274 - accuracy: 0.7969\n",
      "Epoch 98/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5263 - accuracy: 0.7969\n",
      "Epoch 99/200\n",
      "9/9 [==============================] - 0s 664us/step - loss: 0.5253 - accuracy: 0.7980\n",
      "Epoch 100/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5243 - accuracy: 0.7980\n",
      "Epoch 101/200\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.5235 - accuracy: 0.7969\n",
      "Epoch 102/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5223 - accuracy: 0.7969\n",
      "Epoch 103/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5214 - accuracy: 0.8013\n",
      "Epoch 104/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5214 - accuracy: 0.8025\n",
      "Epoch 105/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5195 - accuracy: 0.8013\n",
      "Epoch 106/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5186 - accuracy: 0.8013\n",
      "Epoch 107/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5176 - accuracy: 0.8013\n",
      "Epoch 108/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5171 - accuracy: 0.8002\n",
      "Epoch 109/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5159 - accuracy: 0.8002\n",
      "Epoch 110/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.5149 - accuracy: 0.8025\n",
      "Epoch 111/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5141 - accuracy: 0.8025\n",
      "Epoch 112/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5132 - accuracy: 0.8036\n",
      "Epoch 113/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5123 - accuracy: 0.8036\n",
      "Epoch 114/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5115 - accuracy: 0.8025\n",
      "Epoch 115/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5106 - accuracy: 0.8025\n",
      "Epoch 116/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5099 - accuracy: 0.8025\n",
      "Epoch 117/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5090 - accuracy: 0.8025\n",
      "Epoch 118/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5082 - accuracy: 0.8025\n",
      "Epoch 119/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5075 - accuracy: 0.8025\n",
      "Epoch 120/200\n",
      "9/9 [==============================] - 0s 542us/step - loss: 0.5066 - accuracy: 0.8025\n",
      "Epoch 121/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5057 - accuracy: 0.8025\n",
      "Epoch 122/200\n",
      "9/9 [==============================] - 0s 531us/step - loss: 0.5048 - accuracy: 0.8025\n",
      "Epoch 123/200\n",
      "9/9 [==============================] - 0s 542us/step - loss: 0.5041 - accuracy: 0.8025\n",
      "Epoch 124/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5033 - accuracy: 0.8025\n",
      "Epoch 125/200\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.5024 - accuracy: 0.8025\n",
      "Epoch 126/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.5019 - accuracy: 0.8025\n",
      "Epoch 127/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.5008 - accuracy: 0.8025\n",
      "Epoch 128/200\n",
      "9/9 [==============================] - 0s 551us/step - loss: 0.5004 - accuracy: 0.8025\n",
      "Epoch 129/200\n",
      "9/9 [==============================] - 0s 735us/step - loss: 0.4994 - accuracy: 0.8025\n",
      "Epoch 130/200\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4985 - accuracy: 0.8025\n",
      "Epoch 131/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4976 - accuracy: 0.8025\n",
      "Epoch 132/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4972 - accuracy: 0.8025\n",
      "Epoch 133/200\n",
      "9/9 [==============================] - 0s 666us/step - loss: 0.4965 - accuracy: 0.8036\n",
      "Epoch 134/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4954 - accuracy: 0.8025\n",
      "Epoch 135/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4947 - accuracy: 0.8025\n",
      "Epoch 136/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4945 - accuracy: 0.8025\n",
      "Epoch 137/200\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4932 - accuracy: 0.8025\n",
      "Epoch 138/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4923 - accuracy: 0.8025\n",
      "Epoch 139/200\n",
      "9/9 [==============================] - 0s 778us/step - loss: 0.4916 - accuracy: 0.8036\n",
      "Epoch 140/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4909 - accuracy: 0.8036\n",
      "Epoch 141/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4914 - accuracy: 0.8036\n",
      "Epoch 142/200\n",
      "9/9 [==============================] - 0s 646us/step - loss: 0.4894 - accuracy: 0.8036\n",
      "Epoch 143/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4891 - accuracy: 0.8025\n",
      "Epoch 144/200\n",
      "9/9 [==============================] - 0s 696us/step - loss: 0.4886 - accuracy: 0.8013\n",
      "Epoch 145/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4875 - accuracy: 0.8025\n",
      "Epoch 146/200\n",
      "9/9 [==============================] - 0s 623us/step - loss: 0.4875 - accuracy: 0.8025\n",
      "Epoch 147/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4864 - accuracy: 0.8036\n",
      "Epoch 148/200\n",
      "9/9 [==============================] - 0s 705us/step - loss: 0.4858 - accuracy: 0.8025\n",
      "Epoch 149/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4851 - accuracy: 0.8036\n",
      "Epoch 150/200\n",
      "9/9 [==============================] - 0s 669us/step - loss: 0.4846 - accuracy: 0.8036\n",
      "Epoch 151/200\n",
      "9/9 [==============================] - 0s 643us/step - loss: 0.4846 - accuracy: 0.8036\n",
      "Epoch 152/200\n",
      "9/9 [==============================] - 0s 780us/step - loss: 0.4834 - accuracy: 0.8036\n",
      "Epoch 153/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4829 - accuracy: 0.8036\n",
      "Epoch 154/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4825 - accuracy: 0.8047\n",
      "Epoch 155/200\n",
      "9/9 [==============================] - 0s 662us/step - loss: 0.4819 - accuracy: 0.8047\n",
      "Epoch 156/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4812 - accuracy: 0.8036\n",
      "Epoch 157/200\n",
      "9/9 [==============================] - 0s 700us/step - loss: 0.4813 - accuracy: 0.8036\n",
      "Epoch 158/200\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.4426 - accuracy: 0.87 - 0s 665us/step - loss: 0.4799 - accuracy: 0.8070\n",
      "Epoch 159/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4795 - accuracy: 0.8081\n",
      "Epoch 160/200\n",
      "9/9 [==============================] - 0s 715us/step - loss: 0.4791 - accuracy: 0.8070\n",
      "Epoch 161/200\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4785 - accuracy: 0.8058\n",
      "Epoch 162/200\n",
      "9/9 [==============================] - 0s 654us/step - loss: 0.4780 - accuracy: 0.8047\n",
      "Epoch 163/200\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4778 - accuracy: 0.8092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4770 - accuracy: 0.8070\n",
      "Epoch 165/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4765 - accuracy: 0.8058\n",
      "Epoch 166/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4761 - accuracy: 0.8103\n",
      "Epoch 167/200\n",
      "9/9 [==============================] - 0s 598us/step - loss: 0.4754 - accuracy: 0.8070\n",
      "Epoch 168/200\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.4751 - accuracy: 0.8058\n",
      "Epoch 169/200\n",
      "9/9 [==============================] - 0s 799us/step - loss: 0.4749 - accuracy: 0.8058\n",
      "Epoch 170/200\n",
      "9/9 [==============================] - 0s 661us/step - loss: 0.4744 - accuracy: 0.8047\n",
      "Epoch 171/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4740 - accuracy: 0.8070\n",
      "Epoch 172/200\n",
      "9/9 [==============================] - 0s 589us/step - loss: 0.4732 - accuracy: 0.8103\n",
      "Epoch 173/200\n",
      "9/9 [==============================] - 0s 775us/step - loss: 0.4729 - accuracy: 0.8081\n",
      "Epoch 174/200\n",
      "9/9 [==============================] - 0s 557us/step - loss: 0.4724 - accuracy: 0.8081\n",
      "Epoch 175/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4720 - accuracy: 0.8092\n",
      "Epoch 176/200\n",
      "9/9 [==============================] - 0s 668us/step - loss: 0.4715 - accuracy: 0.8092\n",
      "Epoch 177/200\n",
      "9/9 [==============================] - 0s 656us/step - loss: 0.4714 - accuracy: 0.8058\n",
      "Epoch 178/200\n",
      "9/9 [==============================] - 0s 729us/step - loss: 0.4706 - accuracy: 0.8114\n",
      "Epoch 179/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4706 - accuracy: 0.8070\n",
      "Epoch 180/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4697 - accuracy: 0.8114\n",
      "Epoch 181/200\n",
      "9/9 [==============================] - 0s 773us/step - loss: 0.4697 - accuracy: 0.8081\n",
      "Epoch 182/200\n",
      "9/9 [==============================] - 0s 772us/step - loss: 0.4690 - accuracy: 0.8114\n",
      "Epoch 183/200\n",
      "9/9 [==============================] - 0s 642us/step - loss: 0.4686 - accuracy: 0.8114\n",
      "Epoch 184/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4683 - accuracy: 0.8114\n",
      "Epoch 185/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4679 - accuracy: 0.8126\n",
      "Epoch 186/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4676 - accuracy: 0.8092\n",
      "Epoch 187/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4668 - accuracy: 0.8114\n",
      "Epoch 188/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4666 - accuracy: 0.8103\n",
      "Epoch 189/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4661 - accuracy: 0.8114\n",
      "Epoch 190/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4662 - accuracy: 0.8103\n",
      "Epoch 191/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4657 - accuracy: 0.8081\n",
      "Epoch 192/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4660 - accuracy: 0.8092\n",
      "Epoch 193/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4646 - accuracy: 0.8103\n",
      "Epoch 194/200\n",
      "9/9 [==============================] - 0s 685us/step - loss: 0.4644 - accuracy: 0.8081\n",
      "Epoch 195/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4640 - accuracy: 0.8081\n",
      "Epoch 196/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4640 - accuracy: 0.8092\n",
      "Epoch 197/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4632 - accuracy: 0.8114\n",
      "Epoch 198/200\n",
      "9/9 [==============================] - 0s 665us/step - loss: 0.4637 - accuracy: 0.8058\n",
      "Epoch 199/200\n",
      "9/9 [==============================] - 0s 776us/step - loss: 0.4625 - accuracy: 0.8058\n",
      "Epoch 200/200\n",
      "9/9 [==============================] - 0s 554us/step - loss: 0.4624 - accuracy: 0.8103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1333271c948>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Training the ANN on the Training set\n",
    "ann.fit(X_trimmed_scaled, survived, batch_size=100, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_predict = ann.predict(X_test_trimmed_scaled)\n",
    "y1 = np.array(ann_predict)\n",
    "y1 = (y1 > 0.5).flatten() * 1\n",
    "sol = pd.DataFrame({'PassengerId':ID, 'Survived':y1})\n",
    "sol.to_csv('Solution_ANN.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  50 | elapsed:    7.7s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.2s finished\n",
      "C:\\Users\\16472\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:01:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:01:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\"learning_rate\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\"max_depth\":[1,2,3,4,5,6,8,9,10],\"min_child_weight\":[1,2,3,4,5,6,7,8,9],\"gamma\":[0.0,0.1,0.2,0.3,0.4,0.5],\"colsample_bytree\":[0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\"n_estimators\":[100,200,300,400,500]}\n",
    "classifier = XGBClassifier()\n",
    "random_search = RandomizedSearchCV(classifier, param_distributions=params,n_iter=10,scoring=\"roc_auc\",n_jobs=-1,cv=5,verbose=3)\n",
    "random_search.fit(X_trimmed_scaled, survived)\n",
    "random_search.best_estimator_    \n",
    "\n",
    "XGB = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.5, gamma=0.2,\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "              min_child_weight=1, missing=1, n_estimators=200, n_jobs=1,\n",
    "              nthread=None, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)\n",
    "\n",
    "XGB_fit = XGB.fit(X_trimmed_scaled, survived)\n",
    "\n",
    "pred_XGB = XGB.predict(X_test_trimmed_scaled)\n",
    "train_pred_XGB = XGB.predict(X_trimmed_scaled)\n",
    "\n",
    "#94%\n",
    "sol = pd.DataFrame({'PassengerId':ID, 'Survived':pred_XGB})\n",
    "sol.to_csv('Solution_XGB.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[507  76]\n",
      " [ 42 266]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90       583\n",
      "           1       0.78      0.86      0.82       308\n",
      "\n",
      "    accuracy                           0.87       891\n",
      "   macro avg       0.85      0.87      0.86       891\n",
      "weighted avg       0.87      0.87      0.87       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(train_pred_XGB, survived))\n",
    "print()\n",
    "print(classification_report(train_pred_XGB, survived))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
